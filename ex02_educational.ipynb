{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP 모델을 설계하는 순서\n",
    "## 모듈 임포트하기\n",
    "## 딥러닝 모델을 설계할 때 활용하는 장비 확인하기\n",
    "## MNIST 데이터 다운로드 하기 \n",
    "## 데이터 확인하기\n",
    "## 데이터 확인하기\n",
    "## MLP 모델 설계하기\n",
    "## optimizer, Objective Function\n",
    "## MLP 모델 학습을 진행하면서 학습 데이터에 대한 모델 성능을 확인하는 함수 정의\n",
    "## 학습되는 과정 속에서 거믕 데이터에 대한 모델의 성능을 확인하는 함수 정의하기\n",
    "## MLP 학습을 실행하면서 Train, Test set 의 Loss 및 Test set Accuracy 확인하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module Import\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "Using PyTorch version :  2.9.1 Deviece : mps\n"
     ]
    }
   ],
   "source": [
    "# 설계할 때 활용하는 장ㅂ ㅣ확인 \n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device('mps')\n",
    "    print('mps')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    print(\"cpu\")\n",
    "    \n",
    "print('Using PyTorch version : ', torch.__version__, 'Deviece :', DEVICE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 # 한번 계산 할 때 사용할 데이터 수 \n",
    "EPOCHS = 10 # 한번 전체를 도는 것이 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 데이터 다운로드 (Train Test Split)\n",
    "train_dataset = datasets.MNIST(root = \"../data/MNIST\", \n",
    "                               train = True, \n",
    "                               download = True, \n",
    "                               transform = transforms.ToTensor())\n",
    "\n",
    "test_dataset = datasets.MNIST(root = \"../data/MNIST\", \n",
    "                               train = False,  \n",
    "                               transform = transforms.ToTensor()) # 이미지 파일을 tensor형태로 변경, 한 픽셀은 0 ~ 255 범위의 스칼라 값으로 구성, 이를 0 ~ 1 범위로 정규화\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, \n",
    "                                           batch_size = BATCH_SIZE, #Batch_Size 만큼 데이터를 묶어 1개의 Mini-Batch 구성하기 위해 loader 구성\n",
    "                                           shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, \n",
    "                                           batch_size = BATCH_SIZE, \n",
    "                                           shuffle = False)\n",
    "\n",
    "# loader을 구성하는 이유는 미니배치로 구성하기 위해 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([32, 1, 28, 28]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인하기 \n",
    "for (X_train, y_train) in train_loader:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break\n",
    "\n",
    "\n",
    "# X_train: torch.Size([32, 1, 28, 28]) type: torch.FloatTensor -> 32개의 이미지가 하나의 배치/ 그 이미지는 28 * 28 픽셀의 형태 \n",
    "# y_train: torch.Size([32]) type: torch.LongTensor -> 이미지 하나당 하나의 레이블을 차지하므로, 한 배치의 레이블 수는 32개가 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x100 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 확인하기 2\n",
    "pltsize = 1\n",
    "plt.figure(figsize=(10 * pltsize, pltsize))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[i, :, :, :].numpy().reshape(28, 28), cmap = \"gray_r\")\n",
    "    plt.title('Class: ' + str(y_train[i].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP 모델 설계하기 (Forward propagation)\n",
    "\n",
    "class Net(nn.Module):                      \n",
    "    def __init__(self):                     \n",
    "        super(Net, self).__init__()         # nn.Module 내에 있는 메서드를 상속 받아 이용할 수 있게끔\n",
    "        self.fc1 = nn.Linear(28*28, 512)    # 각 Fully Connected Layer 정의 (input, output)\n",
    "        self.fc2 = nn.Linear(512, 256)      \n",
    "        self.fc3 = nn.Linear(256, 10)       \n",
    "    def forward(self, x) :                  # Forward propagation 정의\n",
    "        x = x.view(-1, 28 * 28)             # MLP는 1차원 데이터만 받지만, 이미지는 2차원데이터 값 => view 메서드를 통해 784 크기의 1차원 데이터로 변환해 진행해야한다. : Flatten 한다 \n",
    "        x = self.fc1(x)                     # __init__() 메서드를 이용해 정의한 첫번째 Fully Connected Layer에 1차원으로 펼친 이미지 넣기\n",
    "        x = F.sigmoid(x)                    # 시그모이드 함수 써서 INPUT으로 변환\n",
    "        x = self.fc2(x)                     \n",
    "        x = F.sigmoid(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, dim = 1)       # log_softmax를 이용해 확률값 계산 => Loss값에 대한 gradient를 원할하게 계산할 수 있기 때문\n",
    "        return x\n",
    "    \n",
    "\n",
    "# 여기서 class의 의미 : Net이 호출되면 이하의 정의한 함수들을 실행한다는 의미\n",
    "\n",
    "# class를 왜 쓰는가? 그래야 gradient 기록? 이 가능하다. \n",
    "    # vs def : def는 기록 안됨. class는 기록 가능 \n",
    "\n",
    "# Dropout + ReLU 함수 적용 방법\n",
    "class Net(nn.Module):                      \n",
    "    def __init__(self):                     \n",
    "        super(Net, self).__init__()         \n",
    "        self.fc1 = nn.Linear(28*28, 512)    \n",
    "        self.fc2 = nn.Linear(512, 256)      \n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "        self.dropout_prob = 0.5             # 퍼센트 설정\n",
    "               \n",
    "    def forward(self, x) :                  \n",
    "        x = x.view(-1, 28 * 28)             \n",
    "        x = self.fc1(x)                     \n",
    "        x = F.relu(x)                       # ReLU 함수 적용\n",
    "        x = F.dropout(x, training = self.training, p = self.dropout_prob)   # dropout 적용                 \n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)                       # ReLU 함수 적용 \n",
    "        x = F.dropout(x, training = self.training, p = self.dropout_prob)   # dropout 적용\n",
    "        x = self.fc3(x)ㄴ\n",
    "        x = F.log_softmax(x, dim = 1)       \n",
    "        return x\n",
    "    \n",
    "# Batch Normalization 적용해보기 \n",
    "class Net(nn.Module):                      \n",
    "    def __init__(self):                     \n",
    "        super(Net, self).__init__()         \n",
    "        self.fc1 = nn.Linear(28*28, 512)    \n",
    "        self.fc2 = nn.Linear(512, 256)      \n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "        self.dropout_prob = 0.5\n",
    "        self.batch_norm1 = nn.BatchNormld(512)  # output 값으로 설정\n",
    "        self.batch_norm2 = nn.BatchNormld(256)  # output 값으로 설정           \n",
    "               \n",
    "    def forward(self, x) :                  \n",
    "        x = x.view(-1, 28 * 28)             \n",
    "        x = self.fc1(x)       \n",
    "        x = self.batch_norm1(x)             # input 넣기 전 표준화\n",
    "        x = F.relu(x)                       \n",
    "        x = F.dropout(x, training = self.training, p = self.dropout_prob)                    \n",
    "        x = self.fc2(x)\n",
    "        x= self.batch_norm2(x)              # input 넣기 전 표준화\n",
    "        x = F.relu(x)                       \n",
    "        x = F.dropout(x, training = self.training, p = self.dropout_prob)  \n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, dim = 1)       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# optimizer, Objective Function 설정하기 (Back propagation)\n",
    "model = Net().to(DEVICE)                    # DEVICE에 MLP 모델 할당\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.5)  # Back Propagation을 이용해 파라미터를 업데이트 할 때 Optimizer 정의 : SGD\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # Adam 모델 사용\n",
    "criterion = nn.CrossEntropyLoss()           # 벌점 이런거 주기 \n",
    "\n",
    "print(model)\n",
    "\n",
    "\n",
    "# momentum은 무슨 파라미터일까? \n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.5)\n",
    "        # model.parameters(): 대상 설정\n",
    "        # lr : 학습률\n",
    "        # momentum : 방향성 파라미터, 수치 조절 의미는 과거의 경험을 얼마나 비중 있게 믿을 것인가? \n",
    "# 다른 optimizer 은 뭐가 있을까? \n",
    "    # Adagrad : 자주 변하는 가중치는 보폭을 줄이고, 드물게 변하는건 보폭을 넓혀서 꼼곰하게\n",
    "    # RMSProp : Adagrad의 단점인 나중에 학습이 멈추는 현상 보완\n",
    "    # Adam : Momentum + RMSProp : 관성도 있고 보폭도 알아서 조절하는 가장 똑똑한 엔진 (대체적으로 많이 사용)\n",
    "# criterion은 뭘까? => Loss 계산 위해서 ....\n",
    "# CrossEntropy는 뭘까? \n",
    "    # 정답과 예측값의 확률이 얼마나 겹치치 않는지를 확인 : 많이 겹칠수록 벌점이 적고, 멀어질수록 기하급수적으로 커짐\n",
    "    # 로그를 씌움 : 맞으면 벌점 X, 틀리면 벌점 더 큼\n",
    "\n",
    "\n",
    "# optimizer, Objective Function 설정하기2 (He Initialization)\n",
    "import torch.nn as isinstance\n",
    "def weight_init(m)\n",
    "    if isinstance(m, nn.Linear):            # nn.Linear에 해당하는 파라미터값만 지정\n",
    "        init.kaiming_uniform_(m.weight.data)# he_initialization 을 이용해 파라미터값 초기화 (kaiming_uniform(m.weight.data) = He initialization)\n",
    "\n",
    "model = Net().to(DEVICE)                    \n",
    "model.apply(weight_init)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.5)\n",
    "criterion = nn.CrossEntropyLoss()         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP 모델 학습을 진행하며 학습 데이터에 대한 모델 성능을 확인하는 함수 정의 \n",
    "def train(model, train_loader, optimizer, log_interval): \n",
    "    model.train()                           # MLP을 학습 상태로 지정\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):   # Mini-Batch 단위로 이미지 데이터가 묶여있음. => 순서대로 MLP 모형 학습\n",
    "        image = image.to(DEVICE)            # 이미지 -> 장치에 할당\n",
    "        label = label.to(DEVICE)            # 라벨 -> 장치에 할당\n",
    "        optimizer.zero_grad()               # 지난번 할당한 것 지우는 것 \n",
    "        \n",
    "        output = model(image)               # 이미지 데이터를 인풋으로 모델을 돌려 아웃풋 계산\n",
    "        loss = criterion(output, label)     # Loss funtion 작동\n",
    "        loss.backward()                     # (auto_grad)계산된 gradient 값을 각 파라미터에 할당\n",
    "        optimizer.step()                    # 업데이트\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch : {} [{} / {}({:.0f}%)]\\tTrain Loss: {:6f}\".format(Epoch, batch_idx * len(image), \n",
    "                                                                                  len(train_loader.dataset), 100. * batch_idx / len(train_loader),\n",
    "                                                                                  loss.item()))\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습되는 과정 속에서 검증 데이터에 대한 모델 성능을 확인하는 함수 정의 \n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()                            # 모델을 평가상태로 지정\n",
    "    test_loss = 0                           # Loss 계산하기 위한 초기 설정\n",
    "    correct = 0                             # 올바르게 분류한 경우 세기 위한 초기설정\n",
    "    \n",
    "    with torch.no_grad():                   # gradient를 통해 파라미터 값이 업데이트되는 현상을 방지\n",
    "        for image, label in test_loader:    # Mini-batch 내에 있는 이미지 데이터와 레이블 데이터에 접근\n",
    "            image = image.to(DEVICE)        \n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)           # 모델의 output 계산\n",
    "            test_loss += criterion(output, label).item()    # 계산된 Output과 장비에 할당된 레이블 데이터를 기존에 정의한 CrossEntropy를 이용해 계산된 걸 test_loss\n",
    "            prediction = output.max(1, keepdim = True)[1]   # 계산된 벡터값 내 가장 큰 값인 위치에 해대 해당하는 위치에 대응하는 클래스로 예측 \n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item() # correct에 맞춘 것 수 저장\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)   # test_loss를 mini-batch 개수만큼 나눠 평균 Loss값으로 계산\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)   # 정답률\n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "# .eval() : 평가모드로 바꿔주는 코드 vs .train()\n",
    "\n",
    "# 답지.view as(예측값) : 정답지하고 '모양' 똑같이 맞추기\n",
    "\n",
    "# 예측값.eq(답지) : 답지와 예측값이 맞는지 안맞는지 / T&F와 동일하게 출력(0, 1)  \n",
    "\n",
    "# with : 해당 루프 허용된 특수한 업무(파일 읽기, 기울기 계산 끄기 등)를 수행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch : 1 [0 / 60000(0%)]\tTrain Loss: 2.526221\n",
      "Train Epoch : 1 [6400 / 60000(11%)]\tTrain Loss: 2.321574\n",
      "Train Epoch : 1 [12800 / 60000(21%)]\tTrain Loss: 2.348643\n",
      "Train Epoch : 1 [19200 / 60000(32%)]\tTrain Loss: 2.311108\n",
      "Train Epoch : 1 [25600 / 60000(43%)]\tTrain Loss: 2.283933\n",
      "Train Epoch : 1 [32000 / 60000(53%)]\tTrain Loss: 2.313536\n",
      "Train Epoch : 1 [38400 / 60000(64%)]\tTrain Loss: 2.260909\n",
      "Train Epoch : 1 [44800 / 60000(75%)]\tTrain Loss: 2.299784\n",
      "Train Epoch : 1 [51200 / 60000(85%)]\tTrain Loss: 2.256424\n",
      "Train Epoch : 1 [57600 / 60000(96%)]\tTrain Loss: 2.264182\n",
      "\n",
      "[EPOCH: 1], \tTest Loss: 0.0700, \tTest Accuracy: 15.57 %\n",
      "\n",
      "Train Epoch : 2 [0 / 60000(0%)]\tTrain Loss: 2.251606\n",
      "Train Epoch : 2 [6400 / 60000(11%)]\tTrain Loss: 2.173314\n",
      "Train Epoch : 2 [12800 / 60000(21%)]\tTrain Loss: 2.206167\n",
      "Train Epoch : 2 [19200 / 60000(32%)]\tTrain Loss: 2.130026\n",
      "Train Epoch : 2 [25600 / 60000(43%)]\tTrain Loss: 1.887710\n",
      "Train Epoch : 2 [32000 / 60000(53%)]\tTrain Loss: 1.908029\n",
      "Train Epoch : 2 [38400 / 60000(64%)]\tTrain Loss: 1.726000\n",
      "Train Epoch : 2 [44800 / 60000(75%)]\tTrain Loss: 1.552071\n",
      "Train Epoch : 2 [51200 / 60000(85%)]\tTrain Loss: 1.434269\n",
      "Train Epoch : 2 [57600 / 60000(96%)]\tTrain Loss: 1.326870\n",
      "\n",
      "[EPOCH: 2], \tTest Loss: 0.0402, \tTest Accuracy: 59.62 %\n",
      "\n",
      "Train Epoch : 3 [0 / 60000(0%)]\tTrain Loss: 1.339489\n",
      "Train Epoch : 3 [6400 / 60000(11%)]\tTrain Loss: 1.181773\n",
      "Train Epoch : 3 [12800 / 60000(21%)]\tTrain Loss: 1.017666\n",
      "Train Epoch : 3 [19200 / 60000(32%)]\tTrain Loss: 0.998725\n",
      "Train Epoch : 3 [25600 / 60000(43%)]\tTrain Loss: 0.979778\n",
      "Train Epoch : 3 [32000 / 60000(53%)]\tTrain Loss: 0.882130\n",
      "Train Epoch : 3 [38400 / 60000(64%)]\tTrain Loss: 0.989204\n",
      "Train Epoch : 3 [44800 / 60000(75%)]\tTrain Loss: 0.854642\n",
      "Train Epoch : 3 [51200 / 60000(85%)]\tTrain Loss: 0.956781\n",
      "Train Epoch : 3 [57600 / 60000(96%)]\tTrain Loss: 0.767455\n",
      "\n",
      "[EPOCH: 3], \tTest Loss: 0.0236, \tTest Accuracy: 77.45 %\n",
      "\n",
      "Train Epoch : 4 [0 / 60000(0%)]\tTrain Loss: 0.842114\n",
      "Train Epoch : 4 [6400 / 60000(11%)]\tTrain Loss: 0.548172\n",
      "Train Epoch : 4 [12800 / 60000(21%)]\tTrain Loss: 0.866408\n",
      "Train Epoch : 4 [19200 / 60000(32%)]\tTrain Loss: 0.713982\n",
      "Train Epoch : 4 [25600 / 60000(43%)]\tTrain Loss: 0.815643\n",
      "Train Epoch : 4 [32000 / 60000(53%)]\tTrain Loss: 0.936261\n",
      "Train Epoch : 4 [38400 / 60000(64%)]\tTrain Loss: 0.581221\n",
      "Train Epoch : 4 [44800 / 60000(75%)]\tTrain Loss: 0.632724\n",
      "Train Epoch : 4 [51200 / 60000(85%)]\tTrain Loss: 0.664391\n",
      "Train Epoch : 4 [57600 / 60000(96%)]\tTrain Loss: 0.493031\n",
      "\n",
      "[EPOCH: 4], \tTest Loss: 0.0177, \tTest Accuracy: 83.13 %\n",
      "\n",
      "Train Epoch : 5 [0 / 60000(0%)]\tTrain Loss: 0.963130\n",
      "Train Epoch : 5 [6400 / 60000(11%)]\tTrain Loss: 0.253299\n",
      "Train Epoch : 5 [12800 / 60000(21%)]\tTrain Loss: 0.469338\n",
      "Train Epoch : 5 [19200 / 60000(32%)]\tTrain Loss: 0.621702\n",
      "Train Epoch : 5 [25600 / 60000(43%)]\tTrain Loss: 0.269050\n",
      "Train Epoch : 5 [32000 / 60000(53%)]\tTrain Loss: 0.336298\n",
      "Train Epoch : 5 [38400 / 60000(64%)]\tTrain Loss: 0.534142\n",
      "Train Epoch : 5 [44800 / 60000(75%)]\tTrain Loss: 0.613778\n",
      "Train Epoch : 5 [51200 / 60000(85%)]\tTrain Loss: 0.251558\n",
      "Train Epoch : 5 [57600 / 60000(96%)]\tTrain Loss: 0.418717\n",
      "\n",
      "[EPOCH: 5], \tTest Loss: 0.0145, \tTest Accuracy: 86.58 %\n",
      "\n",
      "Train Epoch : 6 [0 / 60000(0%)]\tTrain Loss: 0.406798\n",
      "Train Epoch : 6 [6400 / 60000(11%)]\tTrain Loss: 0.321751\n",
      "Train Epoch : 6 [12800 / 60000(21%)]\tTrain Loss: 0.267339\n",
      "Train Epoch : 6 [19200 / 60000(32%)]\tTrain Loss: 0.216053\n",
      "Train Epoch : 6 [25600 / 60000(43%)]\tTrain Loss: 0.485424\n",
      "Train Epoch : 6 [32000 / 60000(53%)]\tTrain Loss: 0.402959\n",
      "Train Epoch : 6 [38400 / 60000(64%)]\tTrain Loss: 0.348193\n",
      "Train Epoch : 6 [44800 / 60000(75%)]\tTrain Loss: 0.552910\n",
      "Train Epoch : 6 [51200 / 60000(85%)]\tTrain Loss: 0.297340\n",
      "Train Epoch : 6 [57600 / 60000(96%)]\tTrain Loss: 0.568893\n",
      "\n",
      "[EPOCH: 6], \tTest Loss: 0.0129, \tTest Accuracy: 88.00 %\n",
      "\n",
      "Train Epoch : 7 [0 / 60000(0%)]\tTrain Loss: 0.352230\n",
      "Train Epoch : 7 [6400 / 60000(11%)]\tTrain Loss: 0.271491\n",
      "Train Epoch : 7 [12800 / 60000(21%)]\tTrain Loss: 0.227476\n",
      "Train Epoch : 7 [19200 / 60000(32%)]\tTrain Loss: 0.708635\n",
      "Train Epoch : 7 [25600 / 60000(43%)]\tTrain Loss: 0.334477\n",
      "Train Epoch : 7 [32000 / 60000(53%)]\tTrain Loss: 0.397668\n",
      "Train Epoch : 7 [38400 / 60000(64%)]\tTrain Loss: 0.568690\n",
      "Train Epoch : 7 [44800 / 60000(75%)]\tTrain Loss: 0.759559\n",
      "Train Epoch : 7 [51200 / 60000(85%)]\tTrain Loss: 0.552228\n",
      "Train Epoch : 7 [57600 / 60000(96%)]\tTrain Loss: 0.498827\n",
      "\n",
      "[EPOCH: 7], \tTest Loss: 0.0120, \tTest Accuracy: 88.98 %\n",
      "\n",
      "Train Epoch : 8 [0 / 60000(0%)]\tTrain Loss: 0.360637\n",
      "Train Epoch : 8 [6400 / 60000(11%)]\tTrain Loss: 0.408932\n",
      "Train Epoch : 8 [12800 / 60000(21%)]\tTrain Loss: 0.327455\n",
      "Train Epoch : 8 [19200 / 60000(32%)]\tTrain Loss: 0.608835\n",
      "Train Epoch : 8 [25600 / 60000(43%)]\tTrain Loss: 0.315312\n",
      "Train Epoch : 8 [32000 / 60000(53%)]\tTrain Loss: 0.179538\n",
      "Train Epoch : 8 [38400 / 60000(64%)]\tTrain Loss: 0.515707\n",
      "Train Epoch : 8 [44800 / 60000(75%)]\tTrain Loss: 0.217827\n",
      "Train Epoch : 8 [51200 / 60000(85%)]\tTrain Loss: 0.323645\n",
      "Train Epoch : 8 [57600 / 60000(96%)]\tTrain Loss: 0.313583\n",
      "\n",
      "[EPOCH: 8], \tTest Loss: 0.0113, \tTest Accuracy: 89.37 %\n",
      "\n",
      "Train Epoch : 9 [0 / 60000(0%)]\tTrain Loss: 0.388069\n",
      "Train Epoch : 9 [6400 / 60000(11%)]\tTrain Loss: 0.171926\n",
      "Train Epoch : 9 [12800 / 60000(21%)]\tTrain Loss: 0.241640\n",
      "Train Epoch : 9 [19200 / 60000(32%)]\tTrain Loss: 0.265392\n",
      "Train Epoch : 9 [25600 / 60000(43%)]\tTrain Loss: 0.590274\n",
      "Train Epoch : 9 [32000 / 60000(53%)]\tTrain Loss: 0.183956\n",
      "Train Epoch : 9 [38400 / 60000(64%)]\tTrain Loss: 0.236254\n",
      "Train Epoch : 9 [44800 / 60000(75%)]\tTrain Loss: 0.229202\n",
      "Train Epoch : 9 [51200 / 60000(85%)]\tTrain Loss: 0.333111\n",
      "Train Epoch : 9 [57600 / 60000(96%)]\tTrain Loss: 0.739918\n",
      "\n",
      "[EPOCH: 9], \tTest Loss: 0.0110, \tTest Accuracy: 89.85 %\n",
      "\n",
      "Train Epoch : 10 [0 / 60000(0%)]\tTrain Loss: 0.190576\n",
      "Train Epoch : 10 [6400 / 60000(11%)]\tTrain Loss: 0.182230\n",
      "Train Epoch : 10 [12800 / 60000(21%)]\tTrain Loss: 0.474042\n",
      "Train Epoch : 10 [19200 / 60000(32%)]\tTrain Loss: 0.257182\n",
      "Train Epoch : 10 [25600 / 60000(43%)]\tTrain Loss: 0.369647\n",
      "Train Epoch : 10 [32000 / 60000(53%)]\tTrain Loss: 0.328122\n",
      "Train Epoch : 10 [38400 / 60000(64%)]\tTrain Loss: 0.137856\n",
      "Train Epoch : 10 [44800 / 60000(75%)]\tTrain Loss: 0.326921\n",
      "Train Epoch : 10 [51200 / 60000(85%)]\tTrain Loss: 0.173166\n",
      "Train Epoch : 10 [57600 / 60000(96%)]\tTrain Loss: 0.348455\n",
      "\n",
      "[EPOCH: 10], \tTest Loss: 0.0105, \tTest Accuracy: 90.15 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MLP 학습을 실행하면서 Train, Test  set의 Loss 및 Test set Accuracy를 확인하기\n",
    "for Epoch in range(1, EPOCHS + 1):\n",
    "    train(model, train_loader, optimizer, log_interval = 200)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} %\\n\".format(Epoch, test_loss, test_accuracy))\n",
    "    \n",
    "\n",
    "# 여기서 log_interval은 뭘까?\n",
    "\n",
    "# \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
